{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52ad7a4c",
   "metadata": {},
   "source": [
    "# Teacher (ChatGPT) ‚Üí Dataset ‚Üí Student (Ollama/Qwen) + Versionado + Knowledge Base Log\n",
    "\n",
    "Este notebook implementa un flujo **m√≠nimo y pr√°ctico**:\n",
    "\n",
    "1. Leer un **PDF** (factura) y extraer **texto plano**\n",
    "2. Llamar a **OpenAI (ChatGPT) como *teacher*** para etiquetar/estructurar la salida en **JSON estricto** (validado con **Pydantic**)\n",
    "3. Preparar una muestra en **JSONL** para entrenar un **SLM en local** (p. ej. Qwen/Llama con LoRA usando una tool de fine-tuning externa)\n",
    "4. Hacer una llamada b√°sica a **Ollama/Qwen** para inferencia (como *student*) usando JSON mode\n",
    "5. Guardar **versiones** (artifacts) y registrar un **log tipo knowledge base** (JSONL + SQLite opcional)\n",
    "\n",
    "> Generado: 2026-01-05\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b63e5a06",
   "metadata": {},
   "source": [
    "## 0) Instalaci√≥n (si hace falta)\n",
    "Ejecuta esta celda si est√°s en un entorno limpio.\n",
    "\n",
    "- `pdfplumber`: extrae texto de PDFs (si el PDF es escaneado, necesitar√°s OCR)\n",
    "- `openai`: SDK OpenAI\n",
    "- `pydantic`: validaci√≥n de JSON\n",
    "- `requests`: llamadas a Ollama\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c2f81cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: 3.13.5 | packaged by Anaconda, Inc. | (main, Jun 12 2025, 16:37:03) [MSC v.1929 64 bit (AMD64)]\n",
      "Platform: Windows-11-10.0.26200-SP0\n"
     ]
    }
   ],
   "source": [
    "# !pip -q install pdfplumber openai pydantic requests python-dotenv\n",
    "\n",
    "import sys, platform\n",
    "print(\"Python:\", sys.version)\n",
    "print(\"Platform:\", platform.platform())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ebc64fd",
   "metadata": {},
   "source": [
    "## 1) Configuraci√≥n\n",
    "Configura:\n",
    "- Ruta del PDF\n",
    "- OpenAI API Key (por env var)\n",
    "- Modelo teacher\n",
    "- Modelo student en Ollama (ej: `qwen2.5:7b-instruct`)\n",
    "- Directorios de salida para versionado y knowledge base\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ebebe1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os, json, hashlib, datetime\n",
    "import pdfplumber\n",
    "import requests\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List, Optional\n",
    "\n",
    "# --- INPUTS ---\n",
    "PDF_PATH = Path(\"facturas_compras_sample01.pdf\")  # cambia si lo necesitas\n",
    "\n",
    "# OpenAI\n",
    "OPENAI_MODEL = \"gpt-4o-mini\"  # teacher: coste bajo + structured outputs\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")  # export OPENAI_API_KEY=...\n",
    "# Ollama\n",
    "OLLAMA_URL = os.getenv(\"OLLAMA_URL\", \"http://localhost:11434\")\n",
    "OLLAMA_MODEL = os.getenv(\"OLLAMA_MODEL\", \"qwen2.5:7b-instruct\")  # aseg√∫rate de tenerlo en ollama\n",
    "\n",
    "# --- OUTPUTS ---\n",
    "RUN_ID = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "ARTIFACTS_DIR = Path(\"artifacts\") / RUN_ID\n",
    "KB_DIR = Path(\"knowledge_base\")\n",
    "ARTIFACTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "KB_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"ARTIFACTS_DIR:\", ARTIFACTS_DIR.resolve())\n",
    "print(\"KB_DIR:\", KB_DIR.resolve())\n",
    "print(\"PDF_PATH exists?\", PDF_PATH.exists())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c33b17fd",
   "metadata": {},
   "source": [
    "## 2) Extraer texto plano del PDF\n",
    "Primero intentamos extraer texto con `pdfplumber`.\n",
    "\n",
    "‚ö†Ô∏è Si el PDF es un escaneo (imagen), `pdfplumber` puede devolver poco texto. En ese caso, usa OCR (Textract/Tesseract).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa30f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_pdfplumber(pdf_path: Path) -> str:\n",
    "    texts = []\n",
    "    with pdfplumber.open(str(pdf_path)) as pdf:\n",
    "        for page in pdf.pages:\n",
    "            t = page.extract_text() or \"\"\n",
    "            texts.append(t)\n",
    "    return \"\\n\\n\".join(texts).strip()\n",
    "\n",
    "raw_text = extract_text_pdfplumber(PDF_PATH)\n",
    "print(\"Chars:\", len(raw_text))\n",
    "print(raw_text[:800])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f8b605c",
   "metadata": {},
   "source": [
    "## 3) Schema Pydantic (salida del teacher y del student)\n",
    "Estructura fija, parseable, ideal para auditor√≠a y entrenamiento.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f783fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SensitivityLabel(BaseModel):\n",
    "    label: int = Field(..., description=\"0=no sensible, 1=sensible\")\n",
    "    confidence: float = Field(..., ge=0.0, le=1.0)\n",
    "    signals: List[str] = Field(default_factory=list)\n",
    "    rationale_short: str\n",
    "\n",
    "    @classmethod\n",
    "    def from_any(cls, obj: object) -> \"SensitivityLabel\":\n",
    "        # helper para validar desde dict o str JSON\n",
    "        if isinstance(obj, str):\n",
    "            return cls.model_validate_json(obj)\n",
    "        return cls.model_validate(obj)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "848c7f95",
   "metadata": {},
   "source": [
    "## 4) Prompt del teacher (ChatGPT)\n",
    "Forzamos JSON estricto (sin texto adicional).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f6470d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEACHER_SYSTEM = (\n",
    "    \"Eres un analista de protecci√≥n de datos. \"\n",
    "    \"Clasifica documentos administrativos/financieros por sensibilidad.\"\n",
    ")\n",
    "\n",
    "TEACHER_INSTRUCTIONS = \"\"\"Devuelve SOLO un JSON v√°lido con esta estructura EXACTA:\n",
    "{\n",
    "  \"label\": 0|1,\n",
    "  \"confidence\": 0.0-1.0,\n",
    "  \"signals\": [\"...\"],\n",
    "  \"rationale_short\": \"una frase corta\"\n",
    "}\n",
    "\n",
    "Criterio:\n",
    "- label=1 (SENSIBLE) si aparece IBAN, NIF/CIF, datos bancarios, datos de pago, identificadores fiscales o informaci√≥n financiera identificable.\n",
    "- label=0 si no hay PII/finanzas identificables.\n",
    "- rationale_short: 1 frase, sin pasos intermedios.\n",
    "\"\"\"\n",
    "\n",
    "def build_teacher_user_prompt(doc_text: str) -> str:\n",
    "    return f\"\"\"Texto del documento:\n",
    "<<<\n",
    "{doc_text}\n",
    ">>>\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4e63f20",
   "metadata": {},
   "source": [
    "## 5) Llamada a OpenAI (teacher) con Structured Outputs + parse Pydantic\n",
    "Este patr√≥n sigue la gu√≠a oficial: schema basado en Pydantic.\n",
    "Si tu SDK no tiene `responses.parse`, usa `response_format=json_schema` manual.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc39fa46",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "def sha256_text(s: str) -> str:\n",
    "    return hashlib.sha256(s.encode(\"utf-8\")).hexdigest()\n",
    "\n",
    "DOC_HASH = sha256_text(raw_text)\n",
    "print(\"DOC_HASH:\", DOC_HASH)\n",
    "\n",
    "def teacher_label_document(doc_text: str) -> SensitivityLabel:\n",
    "    if not OPENAI_API_KEY:\n",
    "        raise RuntimeError(\"OPENAI_API_KEY no est√° configurada en el entorno.\")\n",
    "\n",
    "    client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "\n",
    "    resp = client.responses.parse(\n",
    "        model=OPENAI_MODEL,\n",
    "        instructions=TEACHER_SYSTEM + \"\\n\\n\" + TEACHER_INSTRUCTIONS,\n",
    "        input=build_teacher_user_prompt(doc_text),\n",
    "        text_format=SensitivityLabel,\n",
    "    )\n",
    "    return resp.output_parsed\n",
    "\n",
    "# --- Ejecutar teacher ---\n",
    "# teacher_out = teacher_label_document(raw_text)\n",
    "# print(teacher_out.model_dump())\n",
    "\n",
    "print(\"Descomenta las l√≠neas de arriba para ejecutar la llamada real al teacher.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08497d42",
   "metadata": {},
   "source": [
    "## 6) Guardar artefactos del teacher (versionado)\n",
    "Guardamos texto, label y metadata (modelo/prompt/timestamps).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7471b281",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT_VERSION = \"teacher_sensitivity_v1\"\n",
    "\n",
    "def save_teacher_artifacts(doc_text: str, teacher_out: SensitivityLabel) -> None:\n",
    "    (ARTIFACTS_DIR / \"inputs\").mkdir(exist_ok=True)\n",
    "    (ARTIFACTS_DIR / \"teacher\").mkdir(exist_ok=True)\n",
    "\n",
    "    (ARTIFACTS_DIR / \"inputs\" / f\"{DOC_HASH}.txt\").write_text(doc_text, encoding=\"utf-8\")\n",
    "\n",
    "    meta = {\n",
    "        \"run_id\": RUN_ID,\n",
    "        \"doc_hash\": DOC_HASH,\n",
    "        \"pdf_path\": str(PDF_PATH),\n",
    "        \"prompt_version\": PROMPT_VERSION,\n",
    "        \"teacher_model\": OPENAI_MODEL,\n",
    "        \"created_at\": datetime.datetime.now().isoformat(),\n",
    "    }\n",
    "    (ARTIFACTS_DIR / \"teacher\" / f\"{DOC_HASH}.meta.json\").write_text(\n",
    "        json.dumps(meta, indent=2, ensure_ascii=False), encoding=\"utf-8\"\n",
    "    )\n",
    "    (ARTIFACTS_DIR / \"teacher\" / f\"{DOC_HASH}.label.json\").write_text(\n",
    "        json.dumps(teacher_out.model_dump(), indent=2, ensure_ascii=False), encoding=\"utf-8\"\n",
    "    )\n",
    "\n",
    "# Ejemplo:\n",
    "# save_teacher_artifacts(raw_text, teacher_out)\n",
    "print(\"OK. Cuando tengas teacher_out, llama save_teacher_artifacts(raw_text, teacher_out).\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdab772e",
   "metadata": {},
   "source": [
    "## 7) Preparar dataset JSONL para entrenar un SLM local (student)\n",
    "Esto genera un ejemplo SFT (messages + response).\n",
    "\n",
    "üî¥ Nota: Ollama no entrena por API. Este JSONL lo usar√°s con una tool de fine-tuning (LoRA) en local.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c027ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "STUDENT_SYSTEM = \"Eres un clasificador binario de sensibilidad documental. Responde SOLO JSON v√°lido.\"\n",
    "STUDENT_USER_TEMPLATE = \"\"\"Clasifica sensibilidad (0=no sensible,1=sensible) seg√∫n:\n",
    "- 1 si hay IBAN, NIF/CIF, datos bancarios, datos de pago, identificadores fiscales o info financiera identificable.\n",
    "- 0 si no.\n",
    "Devuelve SOLO JSON con: label, confidence, signals, rationale_short.\n",
    "\n",
    "Texto:\n",
    "<<<\n",
    "{doc_text}\n",
    ">>>\n",
    "\"\"\"\n",
    "\n",
    "def build_sft_example(doc_text: str, teacher_out: SensitivityLabel) -> dict:\n",
    "    return {\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": STUDENT_SYSTEM},\n",
    "            {\"role\": \"user\", \"content\": STUDENT_USER_TEMPLATE.format(doc_text=doc_text)},\n",
    "        ],\n",
    "        \"response\": json.dumps(teacher_out.model_dump(), ensure_ascii=False),\n",
    "        \"meta\": {\n",
    "            \"doc_hash\": DOC_HASH,\n",
    "            \"teacher_model\": OPENAI_MODEL,\n",
    "            \"prompt_version\": PROMPT_VERSION,\n",
    "        },\n",
    "    }\n",
    "\n",
    "def append_jsonl(path: Path, obj: dict) -> None:\n",
    "    with path.open(\"a\", encoding=\"utf-8\") as f:\n",
    "        f.write(json.dumps(obj, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "# Ejemplo:\n",
    "# sft_path = ARTIFACTS_DIR / \"student_train.jsonl\"\n",
    "# append_jsonl(sft_path, build_sft_example(raw_text, teacher_out))\n",
    "print(\"OK. Cuando tengas teacher_out, construye el JSONL con build_sft_example + append_jsonl.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93bfc095",
   "metadata": {},
   "source": [
    "## 8) Llamada a Ollama/Qwen (student) en modo JSON\n",
    "Hacemos inferencia con Ollama `/api/chat` y forzamos `format: \"json\"`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce6b739e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ollama_chat_json(model: str, system: str, user: str) -> dict:\n",
    "    url = f\"{OLLAMA_URL}/api/chat\"\n",
    "    payload = {\n",
    "        \"model\": model,\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": system},\n",
    "            {\"role\": \"user\", \"content\": user},\n",
    "        ],\n",
    "        \"stream\": False,\n",
    "        \"format\": \"json\",\n",
    "    }\n",
    "    r = requests.post(url, json=payload, timeout=120)\n",
    "    r.raise_for_status()\n",
    "    data = r.json()\n",
    "    content = data.get(\"message\", {}).get(\"content\", \"\")\n",
    "    try:\n",
    "        return json.loads(content)\n",
    "    except json.JSONDecodeError:\n",
    "        return {\"_raw\": content, \"_error\": \"not_json\"}\n",
    "\n",
    "# Ejemplo:\n",
    "# student_pred = ollama_chat_json(\n",
    "#     model=OLLAMA_MODEL,\n",
    "#     system=STUDENT_SYSTEM,\n",
    "#     user=STUDENT_USER_TEMPLATE.format(doc_text=raw_text[:4000])\n",
    "# )\n",
    "# print(student_pred)\n",
    "\n",
    "print(\"Descomenta para ejecutar. Requiere Ollama corriendo y el modelo descargado.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "087e3def",
   "metadata": {},
   "source": [
    "## 9) Parse/validaci√≥n del output del student con Pydantic\n",
    "Si falla, tu pipeline puede enviar a revisi√≥n humana o reintentar con prompt m√°s estricto.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "541f3d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_student_output(student_json: dict) -> SensitivityLabel:\n",
    "    return SensitivityLabel.from_any(student_json)\n",
    "\n",
    "# Ejemplo:\n",
    "# student_label = parse_student_output(student_pred)\n",
    "# print(student_label.model_dump())\n",
    "\n",
    "print(\"OK. Listo para validar cuando ejecutes el student.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e7dd15",
   "metadata": {},
   "source": [
    "## 10) Knowledge Base Log (JSONL)\n",
    "Registramos cada documento procesado con:\n",
    "- doc_hash\n",
    "- teacher label\n",
    "- student label\n",
    "- versiones y artifacts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f417352e",
   "metadata": {},
   "outputs": [],
   "source": [
    "KB_EVENTS = KB_DIR / \"events.jsonl\"\n",
    "\n",
    "def log_kb_event(\n",
    "    doc_hash: str,\n",
    "    pdf_path: str,\n",
    "    teacher_out: SensitivityLabel,\n",
    "    student_out: Optional[SensitivityLabel] = None,\n",
    "    notes: Optional[str] = None,\n",
    ") -> dict:\n",
    "    event = {\n",
    "        \"ts\": datetime.datetime.now().isoformat(),\n",
    "        \"doc_hash\": doc_hash,\n",
    "        \"pdf_path\": pdf_path,\n",
    "        \"teacher\": teacher_out.model_dump(),\n",
    "        \"student\": student_out.model_dump() if student_out else None,\n",
    "        \"versions\": {\n",
    "            \"prompt_version\": PROMPT_VERSION,\n",
    "            \"teacher_model\": OPENAI_MODEL,\n",
    "            \"ollama_model\": OLLAMA_MODEL,\n",
    "        },\n",
    "        \"artifacts_dir\": str(ARTIFACTS_DIR),\n",
    "        \"notes\": notes,\n",
    "    }\n",
    "    append_jsonl(KB_EVENTS, event)\n",
    "    return event\n",
    "\n",
    "# Ejemplo:\n",
    "# event = log_kb_event(DOC_HASH, str(PDF_PATH), teacher_out, student_label)\n",
    "print(\"OK. Esto crea knowledge_base/events.jsonl\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "296f14ec",
   "metadata": {},
   "source": [
    "## 11) (Opcional) Knowledge Base en SQLite\n",
    "Si quieres consultas r√°pidas, indexaci√≥n y reporting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df120676",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "\n",
    "KB_DB = KB_DIR / \"kb.sqlite\"\n",
    "\n",
    "def init_kb_db(db_path: Path):\n",
    "    con = sqlite3.connect(str(db_path))\n",
    "    cur = con.cursor()\n",
    "    cur.execute(\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS events (\n",
    "        ts TEXT,\n",
    "        doc_hash TEXT,\n",
    "        pdf_path TEXT,\n",
    "        prompt_version TEXT,\n",
    "        teacher_model TEXT,\n",
    "        ollama_model TEXT,\n",
    "        teacher_json TEXT,\n",
    "        student_json TEXT,\n",
    "        artifacts_dir TEXT,\n",
    "        notes TEXT\n",
    "    )\n",
    "    \"\"\")\n",
    "    cur.execute(\"CREATE INDEX IF NOT EXISTS idx_doc_hash ON events(doc_hash)\")\n",
    "    con.commit()\n",
    "    con.close()\n",
    "\n",
    "def insert_kb_db(db_path: Path, event: dict):\n",
    "    con = sqlite3.connect(str(db_path))\n",
    "    cur = con.cursor()\n",
    "    cur.execute(\n",
    "        \"\"\"INSERT INTO events VALUES (?,?,?,?,?,?,?,?,?,?)\"\"\",\n",
    "        (\n",
    "            event[\"ts\"],\n",
    "            event[\"doc_hash\"],\n",
    "            event[\"pdf_path\"],\n",
    "            event[\"versions\"][\"prompt_version\"],\n",
    "            event[\"versions\"][\"teacher_model\"],\n",
    "            event[\"versions\"][\"ollama_model\"],\n",
    "            json.dumps(event[\"teacher\"], ensure_ascii=False),\n",
    "            json.dumps(event[\"student\"], ensure_ascii=False) if event[\"student\"] else None,\n",
    "            event[\"artifacts_dir\"],\n",
    "            event.get(\"notes\"),\n",
    "        ),\n",
    "    )\n",
    "    con.commit()\n",
    "    con.close()\n",
    "\n",
    "init_kb_db(KB_DB)\n",
    "print(\"KB DB ready:\", KB_DB.resolve())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a925605d",
   "metadata": {},
   "source": [
    "## 12) Ejecutar el flujo completo (pasos)\n",
    "1) Extraer texto (ya lo hicimos)\n",
    "2) Teacher:\n",
    "   - `teacher_out = teacher_label_document(raw_text)`\n",
    "   - `save_teacher_artifacts(raw_text, teacher_out)`\n",
    "3) Dataset para entrenamiento:\n",
    "   - `append_jsonl(ARTIFACTS_DIR/'student_train.jsonl', build_sft_example(raw_text, teacher_out))`\n",
    "4) Student (Ollama):\n",
    "   - `student_pred = ollama_chat_json(...)`\n",
    "   - `student_label = parse_student_output(student_pred)`\n",
    "5) KB log:\n",
    "   - `event = log_kb_event(...)`\n",
    "   - `insert_kb_db(KB_DB, event)`\n",
    "\n",
    "üß† Entrenamiento real del SLM:\n",
    "- Con el JSONL generado, haces fine-tuning (LoRA) con una herramienta local.\n",
    "- Luego creas un modelo en Ollama con un Modelfile y vuelves a evaluar.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
